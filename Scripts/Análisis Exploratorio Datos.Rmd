---
title: "Análisis Exploratorio Datos"
output: html_document
---

## Cargar librerías y lectura de datos:

```{r, message=FALSE}
library(tidyverse)
library(viridis)
library(leaflet)
library(ggplot2)
library(dplyr)
library(GGally)
library(factoextra)
library(cluster)
```

```{r}
#data <- read.csv("Vehicle_Collisions.csv")
```

## Lectura datos (temporal)

Jon:

```{r}
data <- read.csv("/DatosJon/UPNA/3º Ciencia de Datos/S6/Analisis Multivariante y Visualizacion de Datos/Trabajo/Datos/Vehicle_Collisions.csv")
```

Rubén:

```{r}
data <- read.csv("C:/Users/ruben/OneDrive/Escritorio/UPNA/CIENCIA DE DATOS/6ºSemestre/AnalisisMultivarianteVisualizacionDatos/Trabajo Final/Motor_Vehicle_Collisions_-_Crashes.csv")
```

Fermin:

```{r}
data <- read.csv("C:/Users/mintx/Mi unidad/CdD UPNA/.3.2/Analisis multivariante y visualizacion de datos/Trabajo/Vehicle_Collisions.csv")
```

# INTRODUCCION

En nuestro conjunto de datos, se recoje información sobre accidentes de tráfico en la ciudad de Nueva York. La información proviene de la página de datos del gobierno de EEUU, específicamente del apartado correspondiente a la ciudad de Nueva York.

Cada individuo corresponde a un accidente de tráfico, que se representa como una fila en el conjunto de datos. Las columnas incluyen información como la fecha y hora del accidente, la ubicación, el tipo de vehículo, y los factores contribuyentes al accidente entre otros muchos. Los accidentes se han almacenado desde el 1/01/2013 hasta la actualidad.

Son accidentes en los que se ha rellenado un informe policial, por lo que podrían no incluirse algunos accidentes menores o accidentes que no han sido reportados a la policía. Ya que este informe es necesario para los accidentes donde hay fallecidos, o daños de al menos 1000\$.

Además, como la forma de recoger los datos ha ido cambiando a lo largo de los años, es posible que hace años no se almacenase información como puede ser las coordenadas, y que en los últimos años con la implementación de dispositivos electrónicos se almacenen las coordenadas exactas de cada accidente. También habrá diferencias en la información dependiendo de la forma en la que el agente de policia correspondiente haya guardado los datos, ya que no son sensores sin fallo los que determinan la mayoría de variables (como pueden ser el tipo de vehículo o factor contribuyentes de la colisión).

Con todo esto, en nuestro trabajo trataremos de analizar las opciones que nos da el conjunto, e ir mostrando los resultados obtenidos visualmente. Y así poder encontrar patrones, agrupar los datos, o ver si podemos encontrar relación entre las variables que nos permitan entender mejor el problema tratado.

# LIMPIEZA INICIAL Y MUESTREO

En primer lugar, observamos que el dataset contiene más de 2 millones de filas, pero que además muchas de las variables están prácticamente vacías o con información redundante. Además, dada la naturaleza de los datos geolocalizados, hay ejemplos que no contienen esa información y no nos son de ayuda.

Por tanto, vamos a realizar una primera limpieza del dataset, eliminando tanto variables redundantes o con poca información, como ejemplos que no nos aporten la información suficiente.

## Eliminar variables:

-   *ZIP.CODE* (ya tenemos la variable *BOROUGH* que contiene el barrio)
-   *ON.STREET.NAME*, *OFF.STREET.NAME*, *CROSS.STREET.NAME* (es información que ya se almacena en las coordenadas)
-   *VEHICLE.TYPE.CODE.3*, *VEHICLE.TYPE.CODE.4*, *VEHICLE.TYPE.CODE.5* (prácticamente todos son valores nulos)
-   *CONTRIBUTING.FACTOR.VEHICLE.2*, *CONTRIBUTING.FACTOR.VEHICLE.3*, *CONTRIBUTING.FACTOR.VEHICLE.4*, *CONTRIBUTING.FACTOR.VEHICLE.5* (prácticamente todos son valores nulos)
-   *COLLISION_ID* (es un identificador que no aporta información)
-   *LOCATION* (es la combinación exacta de las variables *LATITUDE* Y *LONGITUDE*)

```{r}
data_cleaned <- data |> 
  select(-ZIP.CODE, -ON.STREET.NAME, -OFF.STREET.NAME, -CROSS.STREET.NAME, -VEHICLE.TYPE.CODE.3, -VEHICLE.TYPE.CODE.4, -VEHICLE.TYPE.CODE.5, -COLLISION_ID, -CONTRIBUTING.FACTOR.VEHICLE.5, -CONTRIBUTING.FACTOR.VEHICLE.4, -CONTRIBUTING.FACTOR.VEHICLE.3, -CONTRIBUTING.FACTOR.VEHICLE.2,-LOCATION)
```

Con el filtrado realizado, obtenemos un dataset mucho más manejable en cuanto a variables se refiere, que nos permitirá trabajar mejor el problema. Haciendo un pequeño resumen de las variables que nos quedan:

-   CRASH.DATE: Fecha en la que se produció el accidente (Date)
-   CRASH.TIME: Hora en la que se produció el accidente (Time)
-   BOROUGH: Barrio de Nueva York donde sucedió el accidente (String)
-   LATITUDE/LONGITUDE: Coordenadas geográficas (Int)
-   NUMBER.OF.(PERSONS/PEDESTRIANS/CYCLIST/MOTORIST).(KILLED/INJURIED): Número y tipo de personas implicadas en el accidente, diferenciando heridos y fallecidos (Int)
-   CONTRIBUTING.FACTOR.VEHICLE: Causa principal del accidente (String)
-   VEHICLE.TYPE.CODE.1: Tipo del primero vehiculo implicado (String)
-   VEHICLE.TYPE.CODE.2: Tipo del segundo vehiculo implicado (String)

## Eliminar individuos:

-   Individuos que no tengan *LATITUDE* y/o *LONGITUDE* (No nos sirven para localizar el accidente)
-   Individuos que no tengan ningún Vehiculo implicado en *VEHICLE.TYPE.CODE*
-   Individuos que no tengan barrio *BOROUGH* (ya que tenemos los suficientes que si tienen esa información)
-   Individuos que no tengan una razon que haya causado el accidente *CONTRIBUTING.FACTOR.VEHICLE*
-   Individuos con valor de localización erronea (Coordenadas 0) *LONGITUDE*

```{r}
data_cleaned <- data_cleaned |> 
  filter(
    !is.na(LATITUDE) & !is.na(LONGITUDE),
    !(is.na(VEHICLE.TYPE.CODE.1) & is.na(VEHICLE.TYPE.CODE.2)),
    !(VEHICLE.TYPE.CODE.1 == "" & VEHICLE.TYPE.CODE.2 == ""),
    !(BOROUGH == ""),
    !(CONTRIBUTING.FACTOR.VEHICLE.1 == "Unspecified"),
    !(CONTRIBUTING.FACTOR.VEHICLE.1 == ""),
    !(LATITUDE==0),
    !(LONGITUDE==0))
```

## Renombrar variables:

Antes de empezar a trabajar con los datos, vamos a renombrar ciertas variables para facilitar la programación.

```{r}
data_cleaned <- data_cleaned |> 
  rename(
    DATE = CRASH.DATE,
    TIME = CRASH.TIME,
    NUM_PERSONS_INJURED = NUMBER.OF.PERSONS.INJURED,
    NUM_PERSONS_KILLED = NUMBER.OF.PERSONS.KILLED,
    NUM_PEDESTRIANS_INJURED = NUMBER.OF.PEDESTRIANS.INJURED,
    NUM_PEDESTRIANS_KILLED = NUMBER.OF.PEDESTRIANS.KILLED,
    NUM_CYCLIST_INJURED = NUMBER.OF.CYCLIST.INJURED,
    NUM_CYCLIST_KILLED = NUMBER.OF.CYCLIST.KILLED,
    NUM_MOTORIST_INJURED = NUMBER.OF.MOTORIST.INJURED,
    NUM_MOTORIST_KILLED = NUMBER.OF.MOTORIST.KILLED,
    CAUSE = CONTRIBUTING.FACTOR.VEHICLE.1,
    VEHICLE_1 = VEHICLE.TYPE.CODE.1,
    VEHICLE_2 = VEHICLE.TYPE.CODE.2
  )
  
```

## Eliminación de filas incompletas:

### Personas afectadas

Vamos a comprobar si el número de personas heridas o fallecidas coincide con el número de heridos o fallecidos que se han dado en la fila. Para ello, vamos a crear una tabla con los diferentes tipos de heridos y fallecidos, y luego vamos a comprobar si el número total coincide con el número de personas heridas o fallecidas que se han dado en la fila. 

```{r}
type_injured <- data_cleaned |> 
  select(NUM_PERSONS_INJURED, NUM_PEDESTRIANS_INJURED, NUM_CYCLIST_INJURED, NUM_MOTORIST_INJURED,
         NUM_PERSONS_KILLED, NUM_PEDESTRIANS_KILLED, NUM_CYCLIST_KILLED, NUM_MOTORIST_KILLED) |> 
  pivot_longer(cols = everything(), names_to = 'TYPE_OF_INJURED', values_to = 'NUMBER')

# quiero saber el total de de cada tipo

type_injured |> 
  group_by(TYPE_OF_INJURED) |> 
  summarise(NUMBER = sum(NUMBER)) |> 
  arrange(desc(NUMBER))

# ahora mostramos los indices de los que no coinciden
filas_erroneas <- data_cleaned |> 
  select(NUM_PERSONS_INJURED, NUM_PEDESTRIANS_INJURED, NUM_CYCLIST_INJURED, NUM_MOTORIST_INJURED,
         NUM_PERSONS_KILLED, NUM_PEDESTRIANS_KILLED, NUM_CYCLIST_KILLED, NUM_MOTORIST_KILLED) |> 
  mutate(ROW_ID = row_number(),
         TOTAL_NUMBER_INJURED = rowSums(across(c(NUM_PEDESTRIANS_INJURED, NUM_CYCLIST_INJURED, NUM_MOTORIST_INJURED))),
         TOTAL_NUMBER_KILLED = rowSums(across(c(NUM_PEDESTRIANS_KILLED, NUM_CYCLIST_KILLED, NUM_MOTORIST_KILLED)))) |>
  select(ROW_ID, NUM_PERSONS_INJURED, TOTAL_NUMBER_INJURED, NUM_PERSONS_KILLED, TOTAL_NUMBER_KILLED) |> 
  filter(NUM_PERSONS_INJURED != TOTAL_NUMBER_INJURED | NUM_PERSONS_KILLED != TOTAL_NUMBER_KILLED)

filas_erroneas
```

Podemos ver como existen filas que no cumplen, por ello eliminamos las filas erroneas, aquellas filas cuyo numero de personas heridas o fallecidas no coincide con el total de heridos o fallecidos que se han dado en la fila.


```{r}
indices_erroneos <- filas_erroneas |> 
  pull(ROW_ID)

data_cleaned <- data_cleaned[-indices_erroneos, ]

```

## Eliminacion de valores incorrectos de la variable 'CAUSE'

```{r}
data_cleaned <- data_cleaned |> 
  mutate(CAUSE = recode(CAUSE,
    "Cell Phone (hand-Held)" = "Cell Phone (hand-held)",
    "Drugs (Illegal)" = "Drugs (illegal)",
    "Illnes" = "Illness",
    "Other Electronic Device" = "Other Devices",
    "Drugs (illegal)" = "Drugs (illegal)",
    "Unspecified" = "Unspecified",
    "Pedestrian/Bicyclist/Other Pedestrian Error/Confusion" = "Pedestrian Error/Confusion",
    "Aggressive Driving/Road Rage" = "Aggressive Driving"
  )) |> 
  filter(CAUSE != 1, CAUSE != 80) 
```


## Muestreo:

Una vez eliminados los individuos que no son de interes, el dataset se reduce a 893275 filas. Es más manejable pero seguimos teniendo demasiadas observaciones, por lo que para trabajar con los datos de forma más comoda hemos decidido hacer un muestreo de 20.000 observaciones


```{r}
set.seed(123)
data_sampled <- sample_n(data_cleaned, 20000)
```

Como a partir de ahora trabajaremos con esta muestra en lugar del dataset completo, por comodidad lo almacenaremos en un nuevo archivo para solo tener que leer este.

```{r}
write.csv(data_sampled, "Scripts/data_sampled.csv", row.names = FALSE)
```

### Leer muestra:

```{r}
data_sampled <- read.csv("Scripts/data_sampled.csv")
```

# ANALISIS DESCRIPTIVO

Una vez obtenido el dataset con el que trabajaremos, vamos a visualizar las diferentes variables y sus comportamientos para tratar de entender mejor con que datos estamos trabajando antes de aplicar las diferentes técnicas.

Vamos a mostrar un histograma por cada variable o variables que creamos que van conjuntamente, y así ver la distribución de los datos. Además, también mostraremos la matriz de correlación entre las variables numéricas, para ver si hay alguna relación entre ellas.

```{r}
# Mostramos el histograma de los barrios, además del box plot:
data_sampled |> 
  ggplot(aes(x = BOROUGH)) +
  geom_histogram(stat = "count", fill = "steelblue") +
  labs(title = "Distribución de Accidentes por Barrio",
       x = "Barrio",
       y = "Número de Accidentes")
```

Para el caso de latitude y longitude, vamos a mostrar un mapa con la localización de los accidentes en el mapa de Nueva York. Para ello, vamos a usar la librería leaflet, que nos permite mostrar mapas interactivos.

```{r, results='asis', echo=FALSE}
data_sampled |> 
  leaflet() |> 
  addTiles() |> 
  addCircleMarkers(
    lng = ~LONGITUDE,
    lat = ~LATITUDE,
    radius = 2,
    color = "red",
    stroke = FALSE,
    fillOpacity = 0.6,
    popup = ~paste("Lat:", LATITUDE, "<br>Lon:", LONGITUDE)
  )
```

Ahora, vamos a mostrar un histograma comparando la cantidad de personas heridas frente a la cantidad de personas muertas:

```{r}
# 1. Crear un resumen total
datos_resumen <- data_sampled |> 
  summarise(
    Total_Heridos = sum(NUM_PERSONS_INJURED, na.rm = TRUE),
    Total_Muertos = sum(NUM_PERSONS_KILLED, na.rm = TRUE)
  )

# 2. Reestructurar para graficar
datos_long <- tidyr::pivot_longer(
  datos_resumen,
  cols = everything(),
  names_to = "Tipo",
  values_to = "Personas"
)

# 3. Crear el histograma comparativo
ggplot(datos_long, aes(x = Tipo, y = Personas, fill = Tipo)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = Personas), vjust = -0.5, size = 3, fontface = "bold") +
  labs(title = "Total de personas heridas vs muertas",
       x = "", y = "Número de personas") +
  scale_fill_manual(values = c("firebrick", "darkblue")) +
  theme_minimal()
```

Ahora, podemos comprobar el número de viandantes, ciclistas y motoristas que han resultado heridos o muertos en los accidentes:

```{r, fig.width=15} 
# 1. Crear un resumen total
datos_resumen <- data_sampled |> 
  summarise(
    Total_Heridos = sum(NUM_PERSONS_INJURED, na.rm = TRUE),
    Heridos_Pedestrians = sum(NUM_PEDESTRIANS_INJURED, na.rm = TRUE),
    Heridos_Cyclists = sum(NUM_CYCLIST_INJURED, na.rm = TRUE),
    Heridos_Motorists = sum(NUM_MOTORIST_INJURED, na.rm = TRUE),
    Total_Muertos = sum(NUM_PERSONS_KILLED, na.rm = TRUE),
    Muertos_Pedestrians = sum(NUM_PEDESTRIANS_KILLED, na.rm = TRUE),
    Muertos_Cyclists = sum(NUM_CYCLIST_KILLED, na.rm = TRUE),
    Muertos_Motorists = sum(NUM_MOTORIST_KILLED, na.rm = TRUE)
  )

# 2. Pasar a formato largo
datos_long <- datos_resumen |> 
  pivot_longer(cols = everything(),
               names_to = c("Estado", "Tipo"),
               names_sep = "_",
               values_to = "Total")

# 3. Gráfico separado por estado (herido/muerto)
ggplot(datos_long, aes(x = Tipo, y = Total, fill = Tipo)) +
  geom_col(show.legend = TRUE) +  # Activamos la leyenda
  geom_text(aes(label = Total), vjust = -0.5, size = 4) +
  facet_wrap(~Estado, scales = "free_y") +
  labs(
    title = "Total de personas heridas y muertas por tipo",
    x = NULL,  # Quitamos la etiqueta del eje x
    y = "Total",
    fill = "Tipo de persona"  # Título de la leyenda
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_blank(),       # Oculta los nombres debajo de las barras
    axis.ticks.x = element_blank(),      # Oculta las marcas del eje x
    legend.position = "bottom"           # Posiciona la leyenda debajo del gráfico
  )
```
*El gráfico de la derecha es el mismo que el del anterior chunk, se podría quitar este o el otro, como veais*

*CON LOS TIPOS DE VEHÍCULOS NO SÉ MUY BIEN QUE HACER*

Veamos ahora la matriz de correlación:

```{r, fig.width=15}
ggpairs(data_sampled, columns = c("NUM_PERSONS_INJURED", "NUM_PEDESTRIANS_INJURED", "NUM_CYCLIST_INJURED", "NUM_MOTORIST_INJURED", "NUM_PERSONS_KILLED", "NUM_PEDESTRIANS_KILLED", "NUM_CYCLIST_KILLED", "NUM_MOTORIST_KILLED"), 
        title = "Matriz de Correlación entre Variables")
```
*No se yo si la correlación tiene mucho sentigo hacerlo o si es significativa...*


Vamos a mostrar un histograma por cada variable o variables que creamos que van conjuntamente, y así ver la distribución de los datos. Además, también mostraremos la matriz de correlación entre las variables numéricas, para ver si hay alguna relación entre ellas.

## Variable 'BOROUGH'

```{r}
# Mostramos el histograma de los barrios, además del box plot:
data_sampled |> 
  ggplot(aes(x = BOROUGH)) +
  geom_histogram(stat = "count", fill = "steelblue") +
  labs(title = "Distribución de Accidentes por Barrio",
       x = "Barrio",
       y = "Número de Accidentes")
```


## Variable 'CAUSE'

Primero, vamos a ver la frecuencia de los diferentes factores contribuyentes al accidente. Para ello, vamos a crear una tabla con los diferentes factores contribuyentes y su frecuencia.


```{r}
causes_cleaned <- data_sampled |> 
  count(CAUSE, name = "FREQUENCY") |>  
  arrange(desc(FREQUENCY))

```

Ahora vamos a graficar todos los factores contribuyentes, y su frecuencia. Para ello, vamos a usar un gráfico de barras.

```{r}
causes_cleaned |> 
  ggplot(aes(x = reorder(CAUSE, FREQUENCY), y = FREQUENCY)) + 
  geom_bar(stat = "identity", fill = "steelblue") + 
  # coord_flip() +  # Rota el gráfico para mejor visualización
  labs(title = "Total Frecuencia de Factores Contribuyentes",
       x = "Factor Contribuyente",
       y = "Frecuencia") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle=60, hjust=1,size=6),
        axis.title = element_text(size=10),
        title = element_text(size=12),
        axis.title.x=element_blank(),
        legend.title = element_blank()
        )
```


(Aqui añadir histogramas, matrices de correlacion de las variables, eliminar los individuos localizados muy lejos, distribuciones de cada variable (violines)...)



# METODOLOGÍA MULTIVARIANTE

## PCA

## Componentes principales

## Clusterizaciones

### Variable 'CAUSE'

#### Prueba 1

Vamos a realizar una clusterización de los diferentes factores contribuyentes al accidente. Para ello, vamos a usar el algoritmo K-means, que nos permite agrupar los diferentes factores en diferentes grupos.

```{r}
cause_norm <- causes_cleaned |>
  mutate(FREQUENCY_NORM = scale(FREQUENCY)) |>
  select(CAUSE, FREQUENCY_NORM)

rownames(cause_norm) <- cause_norm$CAUSE
cause_norm <- cause_norm |> 
  select(-CAUSE)

fviz_nbclust(x = cause_norm, 
             FUNcluster = kmeans, 
             method = "wss", 
             k.max = 15, 
             nstart = 50) +
  labs(title = "Número óptimo de clusters (WSS)")

```



```{r}

pam_clusters <- pam(x = cause_norm, k = 4, metric = "manhattan")

# Visualizar con fviz_cluster usando dos dimensiones
# fviz_cluster(pam_clusters, 
#              data = cause_norm,
#              show.clust.cent = TRUE, 
#              ellipse.type = "euclid",
#              star.plot = TRUE, 
#              repel = TRUE) +
#   labs(title = "Resultados clustering K-means (CAUSE)") +
#   theme_bw() + 
#   theme(legend.position = "none")


resultados <- data.frame(ciudad = names(pam_clusters$cluster), cluster = as.factor(pam_clusters$cluster)) |> 
    arrange(cluster)

library(igraph)
library(tidygraph)
library(ggraph)

datos_graph <- graph_from_data_frame(d = resultados, directed = TRUE)
datos_graph <- as_tbl_graph(datos_graph)

# Se añade información sobre a que cluster pertenece cada observacion
datos_graph <- datos_graph |> 
    activate(nodes) |> 
    left_join(resultados, by = c(name = "ciudad"))

ggraph(graph = datos_graph) + 
  geom_edge_link(alpha = 0.5) + 
  geom_node_point(aes(color = cluster)) +
  geom_node_text(aes(label = name), repel = TRUE, alpha = 0.5, size = 3) + 
  labs(title = "Resultados clustering K-means") +
  theme_graph()

```

#### Prueba 2

Realizar PCA con otro tipo de metricas.

1. Crear una matriz de características para cada causa

```{r}

# Ejemplo: sumar heridos y muertos promedio por causa
cause_features <- data_sampled |> 
  group_by(CAUSE) |> 
  summarise(
    N = n(),
    avg_injured = mean(NUM_PERSONS_INJURED, na.rm = TRUE),
    avg_killed = mean(NUM_PERSONS_KILLED, na.rm = TRUE),
    # avg_cyclist_injured = mean(NUM_CYCLIST_INJURED, na.rm = TRUE),
    # avg_motorist_injured = mean(NUM_MOTORIST_INJURED, na.rm = TRUE),
    # avg_pedestrian_injured = mean(NUM_PEDESTRIANS_INJURED, na.rm = TRUE)
  ) |> 
  ungroup()

```

2. Normalizar los datos y aplicar PCA

```{r}
# Normalizar
cause_features_scaled <- cause_features |> 
  column_to_rownames("CAUSE") |> 
  scale()

# PCA
pca_res <- prcomp(cause_features_scaled, center = TRUE, scale. = TRUE)
biplot(pca_res, main = "PCA de las causas")

library(ggbiplot)
ggbiplot(pca_res, choices = c(1,2))
```
3. Clustering

```{r}

# Determinar número de clusters óptimo
fviz_nbclust(cause_features_scaled, kmeans, method = "wss")

# K-means clustering
set.seed(123)
km <- kmeans(cause_features_scaled, centers = 7, nstart = 50)

# Visualizar clusters
fviz_cluster(km, data = cause_features_scaled, 
             show.clust.cent = TRUE, 
             repel = TRUE) +
  theme_minimal() +
  labs(title = "Clustering de causas de accidente")
```
#### Prueba 3

Establecer similitudes entre los nombres de las causas.

```{r}
library(stringdist)

# Crear matriz de distancias entre nombres de causas
dist_matrix <- stringdistmatrix(causes_cleaned$CAUSE, causes_cleaned$CAUSE, method = "jw")  # método Jaro-Winkler, o "lv" para Levenshtein
rownames(dist_matrix) <- causes_cleaned$CAUSE
colnames(dist_matrix) <- causes_cleaned$CAUSE
```

Clustering jerarquico

```{r}
hc <- hclust(as.dist(dist_matrix), method = "ward.D2")
plot(hc, main = "Dendograma de Causas", cex = 0.7)


fviz_dend(x = hc, cex = 0.5, main = "Dendrograma - ward", xlab = "observaciones",
    ylab = "distancia", sub = "", horiz = TRUE)
```

Cortar endograma

```{r, warning=FALSE}
fviz_dend(x = hc,
          k = 8,
          k_colors = c("#1f77b4", "#ff7f0e", "#2ca02c", "#d62728", "#9467bd", "#8c564b",  "#e377c2", "#7f7f7f"),
          color_labels_by_k = TRUE,
          rect = TRUE,
          #rect_border = c("#2E9FDF", "#00AFBB", "#E7B800", "#FC4E07"),
          rect_fill = TRUE,
          cex = 0.5,
          main = "Dendrograma - ward",
          xlab = "observaciones",
          ylab = "distancia",
          sub = "")

fviz_dend(x = hc, k = 8, k_colors = c("#1f77b4", "#ff7f0e", "#2ca02c", "#d62728", "#9467bd", "#8c564b",  "#e377c2", "#7f7f7f"),
    color_labels_by_k = TRUE, cex = 0.5, type = "circular")

```

## Etc

# CONCLUSIONES







# Pruebas

## Contributing Factor Vehicle

```{r}
contr_v1 <- data |> 
  select(CONTRIBUTING.FACTOR.VEHICLE.1) |> 
  mutate(CONTR_V1 = CONTRIBUTING.FACTOR.VEHICLE.1) |> 
  filter(if_any(everything(), ~ . != "")) |> 
  count(CONTR_V1, name='FREQUENCY')

contr_v2 <- data |> 
  select(CONTRIBUTING.FACTOR.VEHICLE.2) |> 
  mutate(CONTR_V2 = CONTRIBUTING.FACTOR.VEHICLE.2) |> 
  filter(if_any(everything(), ~ . != "")) |> 
  count(CONTR_V2, name='FREQUENCY')

contr_v3 <- data |> 
  select(CONTRIBUTING.FACTOR.VEHICLE.3) |> 
  mutate(CONTR_V3 = CONTRIBUTING.FACTOR.VEHICLE.3) |> 
  filter(if_any(everything(), ~ . != "")) |> 
  count(CONTR_V3, name='FREQUENCY')

contr_v4 <- data |> 
  select(CONTRIBUTING.FACTOR.VEHICLE.4) |> 
  mutate(CONTR_V4 = CONTRIBUTING.FACTOR.VEHICLE.4) |> 
  filter(if_any(everything(), ~ . != "")) |> 
  count(CONTR_V4, name='FREQUENCY')

contr_v5 <- data |> 
  select(CONTRIBUTING.FACTOR.VEHICLE.5) |> 
  mutate(CONTR_V5 = CONTRIBUTING.FACTOR.VEHICLE.5) |> 
  filter(if_any(everything(), ~ . != "")) |> 
  count(CONTR_V5, name='FREQUENCY')
```

```{r}
contr_factors_cleaned <- data |> 
  select(starts_with("CONTRIBUTING.FACTOR.VEHICLE")) |>  # Selecciona todas las columnas relevantes
  pivot_longer(cols = everything(), names_to = "VEHICLE", values_to = "FACTOR") |>  # Convierte a formato largo
  filter(FACTOR != "") |>  # Filtra valores vacíos  
  mutate(FACTOR = recode(FACTOR,
    "Cell Phone (hand-Held)" = "Cell Phone (hand-held)",
    "Drugs (Illegal)" = "Drugs (illegal)",
    "Illnes" = "Illness",
    "Other Electronic Device" = "Other Devices",
    "Drugs (illegal)" = "Drugs (illegal)",
    "Unspecified" = "Unspecified",
    "Pedestrian/Bicyclist/Other Pedestrian Error/Confusion" = "Pedestrian Error/Confusion",
    "Aggressive Driving/Road Rage" = "Aggressive Driving"
  )) |> 
  count(FACTOR, name = "FREQUENCY") |>  # Cuenta ocurrencias de cada factor
  arrange(desc(FREQUENCY))  # Ordena de mayor a menor

```

```{r}
contr_factors_cleaned |> 
  arrange(FREQUENCY)
```

```{r}
contr_factors_cleaned |> 
  ggplot(aes(x = reorder(FACTOR, FREQUENCY), y = FREQUENCY)) + 
  geom_bar(stat = "identity", fill = "steelblue") + 
  # coord_flip() +  # Rota el gráfico para mejor visualización
  labs(title = "Total Frecuencia de Factores Contribuyentes",
       x = "Factor Contribuyente",
       y = "Frecuencia") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle=60, hjust=1,size=6),
        axis.title = element_text(size=10),
        title = element_text(size=12),
        axis.title.x=element_blank(),
        legend.title = element_blank()
        )
```

### Vamos a no considerar el factor 'Unspecified'

```{r}
contr_factors_cleaned |> 
  filter(FACTOR != 'Unspecified', FREQUENCY > 50000) |> 
  ggplot(aes(x = reorder(FACTOR, FREQUENCY), y = FREQUENCY, fill = FREQUENCY)) + 
  geom_bar(stat = "identity") + 
  # coord_flip() +  # Rota el gráfico para mejor visualización
  scale_fill_viridis_c(option = "plasma", name = "Frecuencia") +  # Usa la paleta 'plasma' para mejor contraste
  labs(title = "Frecuencia de Factores Contribuyentes en Accidentes",
       x = "Factor Contribuyente",
       y = "Frecuencia") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle=60, hjust=1,size=6),
        axis.text.y = element_text(size=7),
        axis.title = element_text(size=12),
        title = element_text(size=14, face="bold"),
        legend.position = "right")  # Mueve la leyenda a la derecha

contr_factors_cleaned |> 
  filter(FACTOR != 'Unspecified', FREQUENCY < 50000) |> 
  ggplot(aes(x = reorder(FACTOR, FREQUENCY), y = FREQUENCY, fill = FREQUENCY)) + 
  geom_bar(stat = "identity") + 
  # coord_flip() +  # Rota el gráfico para mejor visualización
  scale_fill_viridis_c(option = "plasma", name = "Frecuencia") +  # Usa la paleta 'plasma' para mejor contraste
  labs(title = "Frecuencia de Factores Contribuyentes en Accidentes",
       x = "Factor Contribuyente",
       y = "Frecuencia") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle=60, hjust=1,size=6),
        axis.text.y = element_text(size=7),
        axis.title = element_text(size=12),
        title = element_text(size=14, face="bold"),
        legend.position = "right")  # Mueve la leyenda a la derecha

```

## Vehicle Type Code:

### Jon

```{r}
vehicle_type_cleaned <- data |> 
  select(starts_with("VEHICLE.TYPE.CODE.1")) |>  
  pivot_longer(cols = everything(), names_to = "TYPE", values_to = "FACTOR") |> 
  filter(FACTOR != "") |>  
  count(FACTOR, name = "FREQUENCY") |>
  arrange(desc(FREQUENCY))

```

Paso 1: Calcular la Similitud Entre Todos los Tipos de Vehículos

```{r}
library(stringdist)

# Extraer los nombres únicos de los vehículos
vehicle_types <- unique(vehicle_type_cleaned$FACTOR)

# Crear una matriz de distancias entre todos los nombres
dist_matrix <- stringdistmatrix(vehicle_types, vehicle_types, method = "jw") 

# Convertir la matriz en un formato adecuado para clustering
rownames(dist_matrix) <- vehicle_types
colnames(dist_matrix) <- vehicle_types
```

Paso 2: Aplicar Clustering para Encontrar Grupos Similares

```{r}
# Realizar clustering jerárquico
hc <- hclust(as.dist(dist_matrix), method = "ward.D2")

# Elegir un número de clusters basado en la distancia (puedes ajustar `h`)
clusters <- cutree(hc, h = 0.25)  # Ajusta h entre 0.1 y 0.3 según el resultado

# Crear un dataframe con la asignación de clusters
df_clusters <- data.frame(VEHICLE_TYPE = vehicle_types, CLUSTER = clusters)
```

Paso 3: Unificar los Tipos de Vehículos en una Nueva Columna

```{r}
# Seleccionar un nombre representativo para cada cluster
df_clusters <- df_clusters |> 
  group_by(CLUSTER) |> 
  mutate(STANDARD_NAME = first(VEHICLE_TYPE))  # Puedes cambiar la estrategia de selección

# Unir esta información con los datos originales
vehicle_type_cleaned <- vehicle_type_cleaned |> 
  left_join(df_clusters, by = c("FACTOR" = "VEHICLE_TYPE")) |> 
  mutate(FACTOR = STANDARD_NAME) |> 
  select(-CLUSTER, -STANDARD_NAME)

# Contar la frecuencia de cada tipo unificado
vehicle_type_final <- vehicle_type_cleaned |> 
  count(FACTOR, name = "FREQUENCY") |> 
  arrange(desc(FREQUENCY))
```

### Rubo

```{r}
dataVT <- data |> 
  dplyr::select(VEHICLE.TYPE.CODE.1, VEHICLE.TYPE.CODE.2, VEHICLE.TYPE.CODE.3, VEHICLE.TYPE.CODE.4, VEHICLE.TYPE.CODE.5)

missing_data <- dataVT %>%
  summarise(across(everything(), ~ sum(is.na(.) | (is.numeric(.) & is.nan(.)) | .=="")))

missing_data_long <- missing_data %>%
  pivot_longer(everything(), names_to = "Variable", values_to = "Missing_Count")


# Crear el gráfico de barras
ggplot(missing_data_long, aes(x = Variable, y = Missing_Count, fill = Variable)) +
  geom_col() +  # Gráfico de barras
  labs(
    x = "Variable",  # Etiqueta del eje X
    y = "Número de valores problemáticos",  # Etiqueta del eje Y
    title = "Valores faltantes, no numéricos o cadenas vacías por variable"  # Título
  ) +
  theme_minimal() +  # Tema minimalista
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotar etiquetas del eje X
```

Como tenemos más de 2 millones de datos faltantes en las variables **VEHICLE.TYPE.CODE.3**, **VEHICLE.TYPE.CODE.4** y **VEHICLE.TYPE.CODE.5**. Hemos considerado eliminar las variables, ya que no aportan nada interesante al conjunto de datos.

```{r}
dataVT_filtred <- data |> 
  dplyr::select(VEHICLE.TYPE.CODE.1, VEHICLE.TYPE.CODE.2)
```

### Frecuencia de los datos:

Voy a mostrar los datos que tenemos en cada una de las variables:

```{r}
library(dplyr)
# Primera variable:
type_vehicle_cleaned <- dataVT_filtred |> 
  select(VEHICLE.TYPE.CODE.1) |> 
  pivot_longer(cols = everything(), names_to = "VEHICLE", values_to = "FACTOR") |>  # Convierte a formato largo
  filter(!is.na(FACTOR) & FACTOR != "") |>  # Filtra NA y valores vacíos  
  count(FACTOR, name = "FREQUENCY") |>  # Cuenta ocurrencias de cada factor
  arrange(desc(FREQUENCY))  # Ordena de mayor a menor

type_vehicle_cleaned |> 
  arrange(FREQUENCY)
```

## Mapas

```{r}
data_cleaned |> 
  slice(:200000) |> 
  leaflet() |> 
  addTiles() |> 
  addCircleMarkers(
    lng = ~LONGITUDE,
    lat = ~LATITUDE,
    radius = 2,
    color = "red",
    stroke = FALSE,
    fillOpacity = 0.6,
    popup = ~paste("Lat:", LATITUDE, "<br>Lon:", LONGITUDE)
  )
```
